{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcec961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16f7360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jovyan/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(key=\"79824aa6b958aeebce669281f175fe198eb060dd\", relogin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8593dd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjabroni_ss\u001b[0m (\u001b[33mdungeon_as_fate\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/shares/SR006.nfs2/almas_deepfake_detection/deepfake_detection_models/NPR-DeepfakeDetection/wandb/run-20240810_073737-xxcrj8sv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dungeon_as_fate/npr_full_train/runs/xxcrj8sv' target=\"_blank\">20-class-resnet_2024_08_10_07_37_37</a></strong> to <a href='https://wandb.ai/dungeon_as_fate/npr_full_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dungeon_as_fate/npr_full_train' target=\"_blank\">https://wandb.ai/dungeon_as_fate/npr_full_train</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dungeon_as_fate/npr_full_train/runs/xxcrj8sv' target=\"_blank\">https://wandb.ai/dungeon_as_fate/npr_full_train/runs/xxcrj8sv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /home/jovyan/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
      "100.0%\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"fc1.weight\", \"fc1.bias\". \n\tUnexpected key(s) in state_dict: \"layer3.0.conv1.weight\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.running_var\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.bias\", \"layer3.0.downsample.0.weight\", \"layer3.0.downsample.1.running_mean\", \"layer3.0.downsample.1.running_var\", \"layer3.0.downsample.1.weight\", \"layer3.0.downsample.1.bias\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.running_var\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.bias\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.running_var\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.bias\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.running_var\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.bias\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.running_var\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.bias\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.running_var\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.bias\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.running_var\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.bias\", \"layer4.0.downsample.0.weight\", \"layer4.0.downsample.1.running_mean\", \"layer4.0.downsample.1.running_var\", \"layer4.0.downsample.1.weight\", \"layer4.0.downsample.1.bias\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.running_var\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.bias\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.running_var\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.bias\", \"fc.weight\", \"fc.bias\". \n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([64, 3, 7, 7]) from checkpoint, the shape in current model is torch.Size([64, 3, 3, 3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 75\u001b[0m\n\u001b[1;32m     70\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m create_dataloader(opt)\n\u001b[1;32m     73\u001b[0m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnpr_full_train\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39mopt\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39mtime\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m, time\u001b[38;5;241m.\u001b[39mlocaltime()), config\u001b[38;5;241m=\u001b[39mopt)\n\u001b[0;32m---> 75\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel is running on device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mnext\u001b[39m(model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtestmodel\u001b[39m():\n",
      "File \u001b[0;32m~/shares/SR006.nfs2/almas_deepfake_detection/deepfake_detection_models/NPR-DeepfakeDetection/networks/trainer.py:16\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28msuper\u001b[39m(Trainer, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(opt)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misTrain \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt\u001b[38;5;241m.\u001b[39mcontinue_train:\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mresnet50\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misTrain \u001b[38;5;129;01mor\u001b[39;00m opt\u001b[38;5;241m.\u001b[39mcontinue_train:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m resnet50(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/shares/SR006.nfs2/almas_deepfake_detection/deepfake_detection_models/NPR-DeepfakeDetection/networks/resnet.py:212\u001b[0m, in \u001b[0;36mresnet50\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m model \u001b[38;5;241m=\u001b[39m ResNet(Bottleneck, [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m3\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pretrained:\n\u001b[0;32m--> 212\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_zoo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_urls\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresnet50\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/shares/SR006.nfs2/almas_deepfake_detection/env/cnn-detection-env/lib/python3.12/site-packages/torch/nn/modules/module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"fc1.weight\", \"fc1.bias\". \n\tUnexpected key(s) in state_dict: \"layer3.0.conv1.weight\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.running_var\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.bias\", \"layer3.0.downsample.0.weight\", \"layer3.0.downsample.1.running_mean\", \"layer3.0.downsample.1.running_var\", \"layer3.0.downsample.1.weight\", \"layer3.0.downsample.1.bias\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.running_var\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.bias\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.running_var\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.bias\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.running_var\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.bias\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.running_var\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.bias\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.running_var\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.bias\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.running_var\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.bias\", \"layer4.0.downsample.0.weight\", \"layer4.0.downsample.1.running_mean\", \"layer4.0.downsample.1.running_var\", \"layer4.0.downsample.1.weight\", \"layer4.0.downsample.1.bias\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.running_var\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.bias\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.running_var\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.bias\", \"fc.weight\", \"fc.bias\". \n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([64, 3, 7, 7]) from checkpoint, the shape in current model is torch.Size([64, 3, 3, 3])."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.nn\n",
    "import argparse\n",
    "import wandb\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from validate import validate\n",
    "from data import create_dataloader\n",
    "from networks.trainer import Trainer\n",
    "from options.train_options import TrainOptions\n",
    "from options.test_options import TestOptions\n",
    "from util import Logger\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "def seed_torch(seed=1029):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.enabled = False\n",
    "\n",
    "\n",
    "# test config\n",
    "vals = ['progan', 'stylegan', 'stylegan2', 'biggan', 'cyclegan', 'stargan', 'gaugan', 'deepfake']\n",
    "multiclass = [1, 1, 1, 0, 1, 0, 0, 0]\n",
    "\n",
    "\n",
    "def get_val_opt():\n",
    "    val_opt = TrainOptions().parse(print_options=False)\n",
    "    val_opt.dataroot = '../../CNNDetection_dataset/val/'\n",
    "    val_opt.isTrain = False\n",
    "    val_opt.no_resize = False\n",
    "    val_opt.no_crop = False\n",
    "    val_opt.serial_batches = True\n",
    "    val_opt.classes = []\n",
    "    return val_opt\n",
    "\n",
    "\n",
    "# params\n",
    "opt = TrainOptions().parse()\n",
    "opt.name = \"4-class-resnet-100-epochs\"\n",
    "opt.dataroot = '../../CNNDetection_dataset/'\n",
    "# opt.classes = [\"airplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "opt.classes = [\"car\"]\n",
    "\n",
    "opt.optim = \"adam\"\n",
    "opt.batch_size = 32\n",
    "opt.delr_freq = 10\n",
    "opt.lr = 0.0002\n",
    "opt.niter = 100\n",
    "opt.save_epoch_freq = 20\n",
    "\n",
    "seed_torch(100)\n",
    "Testdataroot = os.path.join(opt.dataroot, 'test')\n",
    "opt.dataroot = '{}/{}/'.format(opt.dataroot, opt.train_split)\n",
    "Logger(os.path.join(opt.checkpoints_dir, opt.name, 'log.log'))\n",
    "print('  '.join(list(sys.argv)) )\n",
    "val_opt = get_val_opt()\n",
    "Testopt = TestOptions().parse(print_options=False)\n",
    "data_loader = create_dataloader(opt)\n",
    "\n",
    "\n",
    "wandb.init(project='npr_full_train', name=opt.name + '_' +time.strftime(\"%Y_%m_%d_%H_%M_%S\", time.localtime()), config=opt)\n",
    "\n",
    "model = Trainer(opt)\n",
    "\n",
    "print(f'Model is running on device: {next(model.model.parameters()).device}')\n",
    "\n",
    "def testmodel():\n",
    "    print('*'*25);accs = [];aps = []\n",
    "    print(time.strftime(\"%Y_%m_%d_%H_%M_%S\", time.localtime()))\n",
    "    for v_id, val in enumerate(vals):\n",
    "        Testopt.dataroot = '{}/{}'.format(Testdataroot, val)\n",
    "        Testopt.classes = os.listdir(Testopt.dataroot) if multiclass[v_id] else ['']\n",
    "        Testopt.no_resize = False\n",
    "        Testopt.no_crop = True\n",
    "        acc, ap, _, _, _, _ = validate(model.model, Testopt)\n",
    "        accs.append(acc);aps.append(ap)\n",
    "        print(\"({} {:10}) acc: {:.1f}; ap: {:.1f}\".format(v_id, val, acc*100, ap*100))\n",
    "        wandb.log({f'{val}_acc': acc, f'{val}_ap': ap, 'step': model.total_steps})\n",
    "    mean_acc = np.array(accs).mean()*100\n",
    "    mean_ap = np.array(aps).mean()*100\n",
    "    \n",
    "    print(\"({} {:10}) acc: {:.1f}; ap: {:.1f}\".format(v_id+1,'Mean', np.array(accs).mean()*100, np.array(aps).mean()*100));print('*'*25) \n",
    "    print(time.strftime(\"%Y_%m_%d_%H_%M_%S\", time.localtime()))\n",
    "    wandb.log({'Mean_acc': mean_acc, 'Mean_ap': mean_ap, 'step': model.total_steps})\n",
    "\n",
    "\n",
    "# model.eval();testmodel()\n",
    "model.train()\n",
    "print(f'cwd: {os.getcwd()}')\n",
    "for epoch in range(opt.niter):\n",
    "    epoch_start_time = time.time()\n",
    "    iter_data_time = time.time()\n",
    "    epoch_iter = 0\n",
    "\n",
    "    wandb.log({'Epoch': epoch + 1, 'step': model.total_steps})\n",
    "\n",
    "\n",
    "    for i, data in enumerate(data_loader):\n",
    "        model.total_steps += 1\n",
    "        epoch_iter += opt.batch_size\n",
    "\n",
    "        model.set_input(data)\n",
    "        model.optimize_parameters()\n",
    "\n",
    "        if model.total_steps % opt.loss_freq == 0:\n",
    "            print(time.strftime(\"%Y_%m_%d_%H_%M_%S\", time.localtime()), \"Train loss: {} at step: {} lr {}\".format(model.loss, model.total_steps, model.lr))\n",
    "            wandb.log({'Train_loss': model.loss, 'step': model.total_steps})\n",
    "\n",
    "\n",
    "    if epoch % opt.save_epoch_freq == 0:\n",
    "        print('saving the model at the end of epoch %d, iters %d' %\n",
    "            (epoch, model.total_steps))\n",
    "        model.save_networks('latest')\n",
    "        model.save_networks(epoch)\n",
    "\n",
    "    if epoch % opt.delr_freq == 0 and epoch != 0:\n",
    "        print(time.strftime(\"%Y_%m_%d_%H_%M_%S\", time.localtime()), 'changing lr at the end of epoch %d, iters %d' %\n",
    "                (epoch, model.total_steps))\n",
    "        model.adjust_learning_rate()\n",
    "\n",
    "    if epoch == 97:\n",
    "        model.save_networks('98_epoch')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    acc, ap = validate(model.model, val_opt)[:2]\n",
    "    wandb.log({'Val_accuracy': acc, 'Val_ap': ap, 'step': model.total_steps, 'Epoch': epoch + 1})\n",
    "    print(\"(Val @ epoch {}) acc: {}; ap: {}\".format(epoch, acc, ap))\n",
    "    testmodel()\n",
    "    model.train()\n",
    "\n",
    "# model.eval();testmodel()\n",
    "model.save_networks('last')\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
