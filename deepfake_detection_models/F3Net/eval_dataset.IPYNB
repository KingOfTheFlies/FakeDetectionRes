{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, accuracy_score\n",
    "from options.test_options import TestOptions\n",
    "from data import create_dataloader\n",
    "\n",
    "\n",
    "def validate(model, opt):\n",
    "    data_loader = create_dataloader(opt)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_true, y_pred = [], []\n",
    "        for img, label in data_loader:\n",
    "            in_tens = img.cuda()\n",
    "            y_pred.extend(model.forward(in_tens).sigmoid().flatten().tolist())\n",
    "            y_true.extend(label.flatten().tolist())\n",
    "\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    r_acc = accuracy_score(y_true[y_true==0], y_pred[y_true==0] > 0.5)\n",
    "    f_acc = accuracy_score(y_true[y_true==1], y_pred[y_true==1] > 0.5)\n",
    "    acc = accuracy_score(y_true, y_pred > 0.5)\n",
    "    ap = average_precision_score(y_true, y_pred)\n",
    "    return acc, ap, r_acc, f_acc, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "del model.model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_path ./pretrained/xception-b5690688.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/shares/SR006.nfs2/almas_deepfake_detection/deepfake_detection_models/F3Net/models.py:240: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(pretrained_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ForenSynths\n",
      "2024_07_29_12_02_00\n",
      "(0 biggan      ) acc: 48.9; ap: 50.0\n",
      "(1 crn         ) acc: 50.8; ap: 48.9\n",
      "(2 cyclegan    ) acc: 52.3; ap: 51.3\n",
      "(3 deepfake    ) acc: 50.4; ap: 53.2\n",
      "(4 gaugan      ) acc: 50.5; ap: 50.0\n",
      "(5 imle        ) acc: 48.3; ap: 43.3\n",
      "(6 progan      ) acc: 50.2; ap: 50.7\n",
      "(7 san         ) acc: 52.7; ap: 53.6\n",
      "(8 seeingdark  ) acc: 54.2; ap: 53.2\n",
      "(9 stargan     ) acc: 50.1; ap: 51.1\n",
      "(10 stylegan    ) acc: 49.0; ap: 42.2\n",
      "(11 stylegan2   ) acc: 49.2; ap: 45.3\n",
      "(12 whichfaceisreal) acc: 48.4; ap: 46.2\n",
      "(13 Mean      ) acc: 50.4; ap: 49.2\n",
      "*************************\n",
      "GANGen-Detection\n",
      "2024_07_29_12_13_45\n",
      "(0 AttGAN      ) acc: 52.5; ap: 53.3\n",
      "(1 BEGAN       ) acc: 50.0; ap: 54.8\n",
      "(2 MMDGAN      ) acc: 50.0; ap: 53.9\n",
      "(3 RelGAN      ) acc: 55.1; ap: 56.5\n",
      "(4 S3GAN       ) acc: 53.0; ap: 54.6\n",
      "(5 SNGAN       ) acc: 50.0; ap: 51.6\n",
      "(6 STGAN       ) acc: 50.0; ap: 59.4\n",
      "(7 CramerGAN   ) acc: 50.0; ap: 52.3\n",
      "(8 InfoMaxGAN  ) acc: 50.0; ap: 43.2\n",
      "(9 Mean      ) acc: 51.2; ap: 53.3\n",
      "*************************\n",
      "DiffusionForensics\n",
      "2024_07_29_12_16_52\n",
      "(0 iddpm       ) acc: 53.8; ap: 57.8\n",
      "(1 dalle2      ) acc: 49.3; ap: 30.7\n",
      "(2 ddpm        ) acc: 48.2; ap: 49.9\n",
      "(3 if          ) acc: 65.1; ap: 53.8\n",
      "(4 adm         ) acc: 49.7; ap: 48.2\n",
      "(5 ldm         ) acc: 54.5; ap: 55.5\n",
      "(6 pndm        ) acc: 53.8; ap: 63.2\n",
      "(7 sdv1        ) acc: 51.0; ap: 66.0\n",
      "(8 sdv2        ) acc: 53.5; ap: 51.7\n",
      "(9 diff-projectedgan) acc: 52.4; ap: 56.4\n",
      "(10 diff-stylegan) acc: 53.2; ap: 53.3\n",
      "(11 midjourney  ) acc: 51.9; ap: 7.1\n",
      "(12 projectedgan) acc: 52.5; ap: 55.1\n",
      "(13 stylegan_official) acc: 52.6; ap: 54.9\n",
      "(14 vqdiffusion ) acc: 42.3; ap: 37.3\n",
      "(15 Mean      ) acc: 52.3; ap: 49.4\n",
      "*************************\n",
      "UniversalFakeDetect\n",
      "2024_07_29_12_23_11\n",
      "(0 dalle       ) acc: 50.8; ap: 56.7\n",
      "(1 guided      ) acc: 50.0; ap: 48.2\n",
      "(2 ldm_100     ) acc: 50.8; ap: 55.9\n",
      "(3 ldm_200     ) acc: 51.7; ap: 57.5\n",
      "(4 glide_100_10) acc: 53.0; ap: 57.1\n",
      "(5 glide_100_27) acc: 52.8; ap: 57.9\n",
      "(6 glide_50_27 ) acc: 53.0; ap: 56.3\n",
      "(7 ldm_200_cfg ) acc: 49.3; ap: 54.3\n",
      "(8 Mean      ) acc: 51.4; ap: 55.5\n",
      "*************************\n",
      "Diffusion1kStep\n",
      "2024_07_29_12_24_55\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 7.\nOriginal Traceback (most recent call last):\n  File \"/home/jovyan/shares/SR006.nfs2/almas_deepfake_detection/env/almas-env/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/jovyan/shares/SR006.nfs2/almas_deepfake_detection/env/almas-env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n  File \"/home/jovyan/shares/SR006.nfs2/almas_deepfake_detection/env/almas-env/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 317, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/home/jovyan/shares/SR006.nfs2/almas_deepfake_detection/env/almas-env/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 174, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/jovyan/shares/SR006.nfs2/almas_deepfake_detection/env/almas-env/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 174, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/jovyan/shares/SR006.nfs2/almas_deepfake_detection/env/almas-env/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/home/jovyan/shares/SR006.nfs2/almas_deepfake_detection/env/almas-env/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 213, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\nRuntimeError: Trying to resize storage that is not resizable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 82\u001b[0m\n\u001b[1;32m     80\u001b[0m opt\u001b[38;5;241m.\u001b[39mno_resize \u001b[38;5;241m=\u001b[39m DetectionTests[testSet][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_resize\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     81\u001b[0m opt\u001b[38;5;241m.\u001b[39mno_crop   \u001b[38;5;241m=\u001b[39m DetectionTests[testSet][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_crop\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 82\u001b[0m acc, ap, _, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m accs\u001b[38;5;241m.\u001b[39mappend(acc)\n\u001b[1;32m     84\u001b[0m aps\u001b[38;5;241m.\u001b[39mappend(ap)\n",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(model, opt)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     12\u001b[0m     y_true, y_pred \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m img, label \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[1;32m     14\u001b[0m         in_tens \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     15\u001b[0m         y_pred\u001b[38;5;241m.\u001b[39mextend(model\u001b[38;5;241m.\u001b[39mforward(in_tens)\u001b[38;5;241m.\u001b[39msigmoid()\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mtolist())\n",
      "File \u001b[0;32m~/shares/SR006.nfs2/almas_deepfake_detection/env/almas-env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/shares/SR006.nfs2/almas_deepfake_detection/env/almas-env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1324\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rcvd_idx]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1323\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rcvd_idx)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m-> 1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1327\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data()\n",
      "File \u001b[0;32m~/shares/SR006.nfs2/almas_deepfake_detection/env/almas-env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1370\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1370\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/shares/SR006.nfs2/almas_deepfake_detection/env/almas-env/lib/python3.9/site-packages/torch/_utils.py:706\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 706\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 7.\nOriginal Traceback (most recent call last):\n  File \"/home/jovyan/shares/SR006.nfs2/almas_deepfake_detection/env/almas-env/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/jovyan/shares/SR006.nfs2/almas_deepfake_detection/env/almas-env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n  File \"/home/jovyan/shares/SR006.nfs2/almas_deepfake_detection/env/almas-env/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 317, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/home/jovyan/shares/SR006.nfs2/almas_deepfake_detection/env/almas-env/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 174, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/jovyan/shares/SR006.nfs2/almas_deepfake_detection/env/almas-env/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 174, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/jovyan/shares/SR006.nfs2/almas_deepfake_detection/env/almas-env/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 142, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/home/jovyan/shares/SR006.nfs2/almas_deepfake_detection/env/almas-env/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 213, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\nRuntimeError: Trying to resize storage that is not resizable\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "from options.test_options import TestOptions\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from trainer import Trainer\n",
    "\n",
    "DetectionTests = {\n",
    "                'ForenSynths': { 'dataroot'   : '../../datasets/ForenSynths/',\n",
    "                                 'no_resize'  : True,\n",
    "                                 'no_crop'    : False,\n",
    "                               },\n",
    "\n",
    "           'GANGen-Detection': { 'dataroot'   : '../../datasets/GANGen-Detection/',\n",
    "                                 'no_resize'  : True,\n",
    "                                 'no_crop'    : False,\n",
    "                               },\n",
    "\n",
    "         'DiffusionForensics': { 'dataroot'   : '../../datasets/DiffusionForensics/',\n",
    "                                 'no_resize'  : True,\n",
    "                                 'no_crop'    : False,\n",
    "                               },\n",
    "\n",
    "        'UniversalFakeDetect': { 'dataroot'   : '../../datasets/UniversalFakeDetect/',\n",
    "                                 'no_resize'  : True,\n",
    "                                 'no_crop'    : False,\n",
    "                               },\n",
    "\n",
    "        'Diffusion1kStep': { 'dataroot'   : '../../datasets/Diffusion1kStep/',\n",
    "                                 'no_resize'  : True,\n",
    "                                 'no_crop'    : True,\n",
    "                               },\n",
    "\n",
    "                 }\n",
    "\n",
    "\n",
    "opt = TestOptions()\n",
    "\n",
    "# params\n",
    "opt.model_path = './pretrained/xception-b5690688.pth'\n",
    "opt.batch_size = 256\n",
    "opt.isTrain = False\n",
    "opt.mode = 'binary'\n",
    "opt.class_bal = False\n",
    "opt.eval = True\n",
    "opt.num_threads = 8\n",
    "opt.rz_interp = ['bilinear']\n",
    "opt.loadSize = 256\n",
    "opt.blur_prob = 0\n",
    "opt.jpg_prob = 0\n",
    "opt.cropSize = 299\n",
    "\n",
    "print(f'Model_path {opt.model_path}')\n",
    "torch.cuda.set_device('cuda:0')\n",
    "\n",
    "# get model\n",
    "mode = \"Both\"\n",
    "model = Trainer([0], mode, opt.model_path)\n",
    "# model.load(opt.model_path)\n",
    "model.model.eval()\n",
    "model.model.cuda()\n",
    "\n",
    "results = []\n",
    "\n",
    "for testSet in DetectionTests.keys():\n",
    "    dataroot = DetectionTests[testSet]['dataroot']\n",
    "    print(testSet)\n",
    "\n",
    "    accs = []\n",
    "    aps = []\n",
    "    print(time.strftime(\"%Y_%m_%d_%H_%M_%S\", time.localtime()))\n",
    "    for v_id, val in enumerate(os.listdir(dataroot)):\n",
    "        opt.dataroot = '{}/{}'.format(dataroot, val)\n",
    "        opt.classes  = '' #os.listdir(opt.dataroot) if multiclass[v_id] else ['']\n",
    "        opt.no_resize = DetectionTests[testSet]['no_resize']\n",
    "        opt.no_crop   = DetectionTests[testSet]['no_crop']\n",
    "        acc, ap, _, _, _, _ = validate(model, opt)\n",
    "        accs.append(acc)\n",
    "        aps.append(ap)\n",
    "        print(\"({} {:12}) acc: {:.1f}; ap: {:.1f}\".format(v_id, val, acc*100, ap*100))\n",
    "        results.append({'group': testSet, 'id': v_id, 'dataset': val, 'accuracy': acc * 100, 'average_precision': ap * 100})\n",
    "    results.append({'group': testSet, 'id': v_id + 1, 'dataset': 'Mean', 'accuracy': np.array(accs).mean() * 100, 'average_precision': np.array(aps).mean() * 100})    #TODO: изменить dataframe\n",
    "    print(\"({} {:10}) acc: {:.1f}; ap: {:.1f}\".format(v_id+1,'Mean', np.array(accs).mean()*100, np.array(aps).mean()*100))\n",
    "    print('*'*25) \n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv('F3Net_results.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
